{
    "benchmark_datacatalog.TimeDataCatalog.time_contains": {
        "code": "class TimeDataCatalog:\n    def time_contains(self):\n        \"\"\"Benchmark the time to check if a dataset exists\"\"\"\n        for i in range(1,1001):\n            f\"dataset_{i}\" in self.catalog\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4e3a91a7c35589e8c62f3f8e5fd1d2651113c6da5ad2c866d7c8f14172979c53",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_exists": {
        "code": "class TimeDataCatalog:\n    def time_exists(self):\n        \"\"\"Benchmark the time to check if datasets exist\"\"\"\n        for i in range(1,1001):\n            self.catalog.exists(f\"dataset_{i}\")\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_exists",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cc04d61ac7d1fd11981c17220deae43ceb4e44acce906bd4e649fa90a80580df",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_get": {
        "code": "class TimeDataCatalog:\n    def time_get(self):\n        \"\"\"Benchmark the time to get a dataset\"\"\"\n        for i in range(1,1001):\n            self.catalog.get(f\"dataset_{i}\")\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_get",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "dbab78585759d091fac7ecc0f240ca6aa22c82341c5ba6063959ef7d08cc8d78",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_getitem": {
        "code": "class TimeDataCatalog:\n    def time_getitem(self):\n        \"\"\"Benchmark the time to get a dataset\"\"\"\n        for i in range(1,1001):\n            self.catalog[f\"dataset_{i}\"]\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_getitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f0977d3433490a5d1e8deac062c8e855bac6838784e922428f91bc99f28e453c",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_init": {
        "code": "class TimeDataCatalog:\n    def time_init(self):\n        \"\"\"Benchmark the time to initialize the catalog\"\"\"\n        DataCatalog.from_config(base_catalog)\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_init",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cf8f82e6aa228448a9c07efa61fee301874194b9c173e1558dc1a1010c7311f0",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_items": {
        "code": "class TimeDataCatalog:\n    def time_items(self):\n        \"\"\"Benchmark the time to get the items of the catalog\"\"\"\n        self.catalog.items()\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_items",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0b4179d0bb6d68f2f5b91240e6ffaeab593544b4d1f3efac001095ea96b1a4cd",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_iter": {
        "code": "class TimeDataCatalog:\n    def time_iter(self):\n        \"\"\"Benchmark the time to iterate over the catalog\"\"\"\n        for dataset in self.catalog:\n            pass\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_iter",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c28ca7960d8e32b8a66aab57f03981391d7e5831ed8ad3f925530f50e3460359",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_keys": {
        "code": "class TimeDataCatalog:\n    def time_keys(self):\n        \"\"\"Benchmark the time to get the keys of the catalog\"\"\"\n        self.catalog.keys()\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_keys",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "b507a0d5d5365db911b01c1ff06f7ef4e2682b0ee0394a64245b2f229e7c663e",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_load": {
        "code": "class TimeDataCatalog:\n    def time_load(self):\n        \"\"\"Benchmark the time to load datasets\"\"\"\n        for i in range(1,1001):\n            self.catalog.load(f\"dataset_load_{i}\")\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_load",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1896f1b871f31f2f8e4256ca635e8d88248e2cb5e616cf748621ceb36d4cdca2",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_release": {
        "code": "class TimeDataCatalog:\n    def time_release(self):\n        \"\"\"Benchmark the time to release datasets\"\"\"\n        for i in range(1,1001):\n            self.catalog.release(f\"dataset_{i}\")\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_release",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "da1878a7be3473b595650ff9091db9c625bda6541b5f6fc37f003322e874a609",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_resolve_factory": {
        "code": "class TimeDataCatalog:\n    def time_resolve_factory(self):\n        \"\"\"Benchmark the time to resolve factory\"\"\"\n        for i in range(1,1001):\n            self.catalog.get(f\"dataset_factory_{i}\")\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_resolve_factory",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "81f037275034f33bdda52580d02b49ca45e6a622922865e4be58bde7f7277898",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_save": {
        "code": "class TimeDataCatalog:\n    def time_save(self):\n        \"\"\"Benchmark the time to save datasets\"\"\"\n        for i in range(1,1001):\n            self.catalog.save(f\"dataset_{i}\", self.dataframe)\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_save",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "81a2aa66312f2220d201215f2555119dd179689602b4253ed51f9032dec14866",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_setitem": {
        "code": "class TimeDataCatalog:\n    def time_setitem(self):\n        \"\"\"Benchmark the time to set a dataset\"\"\"\n        for i in range(1,1001):\n            self.catalog[f\"dataset_new_{i}\"] = CSVDataset(filepath=\"data.csv\")\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a5871ba83aea593b53dc142d80cf7d61c055381934377a7e46720ee7aa49abbc",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_setitem_raw": {
        "code": "class TimeDataCatalog:\n    def time_setitem_raw(self):\n        \"\"\"Benchmark the time to add a memory dataset\"\"\"\n        for i in range(1,1001):\n            self.catalog[f\"param_{i}\"] = self.parameters[f\"param_{i}\"]\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_setitem_raw",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "470e29181893dc80953a9c761c118013e7560030cfab211a045bb19876aa800c",
        "warmup_time": -1
    },
    "benchmark_datacatalog.TimeDataCatalog.time_values": {
        "code": "class TimeDataCatalog:\n    def time_values(self):\n        \"\"\"Benchmark the time to get the items of the catalog\"\"\"\n        self.catalog.values()\n\n    def setup(self):\n        self.catalog = DataCatalog.from_config(base_catalog)\n        self.dataframe = pd.DataFrame({\"column\": [1, 2, 3]})\n        self.dataframe.to_csv(\"data.csv\", index=False)\n        self.datasets = {\n            f\"dataset_new_{i}\": CSVDataset(filepath=\"data.csv\") for i in range(1, 1001)\n        }\n        self.parameters = {\n            f\"param_{i}\": i for i in range(1, 1001)\n        }",
        "min_run_count": 2,
        "name": "benchmark_datacatalog.TimeDataCatalog.time_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f1a2d6c2a7bb0023dad9d2c3236912815e0b0fa7bb21a1e39c9116434dcb6f2e",
        "warmup_time": -1
    },
    "benchmark_ocl.TimeOmegaConfigLoader.time_loading_catalog": {
        "code": "class TimeOmegaConfigLoader:\n    def time_loading_catalog(self):\n        \"\"\"Benchmark the time to load the catalog\"\"\"\n        self.loader[\"catalog\"]\n\n    def setup(self):\n        # Setup temporary configuration directory with sample config files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.conf_source = Path(self.temp_dir.name)\n    \n        # Create sample config files in the temp directory\n        _create_config_file(self.conf_source, \"base\", \"catalog.yml\", base_catalog)\n        _create_config_file(self.conf_source, \"local\", \"catalog.yml\", local_catalog)\n        _create_config_file(self.conf_source, \"base\", \"parameters.yml\", base_params)\n        _create_config_file(self.conf_source, \"local\", \"parameters.yml\", local_params)\n        _create_config_file(self.conf_source, \"base\", \"globals.yml\", base_globals)\n        _create_config_file(self.conf_source, \"local\", \"globals.yml\", local_globals)\n    \n        # Instantiate the OmegaConfigLoader\n        self.loader = OmegaConfigLoader(conf_source=self.conf_source, base_env='base', default_run_env='local')",
        "min_run_count": 2,
        "name": "benchmark_ocl.TimeOmegaConfigLoader.time_loading_catalog",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3ccff2348faeaf3038548994686b45deeaa3c7c46df2270a8a1f697e7401ae5a",
        "warmup_time": -1
    },
    "benchmark_ocl.TimeOmegaConfigLoader.time_loading_globals": {
        "code": "class TimeOmegaConfigLoader:\n    def time_loading_globals(self):\n        \"\"\"Benchmark the time to load global configuration\"\"\"\n        self.loader[\"globals\"]\n\n    def setup(self):\n        # Setup temporary configuration directory with sample config files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.conf_source = Path(self.temp_dir.name)\n    \n        # Create sample config files in the temp directory\n        _create_config_file(self.conf_source, \"base\", \"catalog.yml\", base_catalog)\n        _create_config_file(self.conf_source, \"local\", \"catalog.yml\", local_catalog)\n        _create_config_file(self.conf_source, \"base\", \"parameters.yml\", base_params)\n        _create_config_file(self.conf_source, \"local\", \"parameters.yml\", local_params)\n        _create_config_file(self.conf_source, \"base\", \"globals.yml\", base_globals)\n        _create_config_file(self.conf_source, \"local\", \"globals.yml\", local_globals)\n    \n        # Instantiate the OmegaConfigLoader\n        self.loader = OmegaConfigLoader(conf_source=self.conf_source, base_env='base', default_run_env='local')",
        "min_run_count": 2,
        "name": "benchmark_ocl.TimeOmegaConfigLoader.time_loading_globals",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d42dda2b001097642dc790de01ab15e3f1f11426f6bfc5affbc1c658248f32be",
        "warmup_time": -1
    },
    "benchmark_ocl.TimeOmegaConfigLoader.time_loading_parameters": {
        "code": "class TimeOmegaConfigLoader:\n    def time_loading_parameters(self):\n        \"\"\"Benchmark the time to load the parameters\"\"\"\n        self.loader[\"parameters\"]\n\n    def setup(self):\n        # Setup temporary configuration directory with sample config files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.conf_source = Path(self.temp_dir.name)\n    \n        # Create sample config files in the temp directory\n        _create_config_file(self.conf_source, \"base\", \"catalog.yml\", base_catalog)\n        _create_config_file(self.conf_source, \"local\", \"catalog.yml\", local_catalog)\n        _create_config_file(self.conf_source, \"base\", \"parameters.yml\", base_params)\n        _create_config_file(self.conf_source, \"local\", \"parameters.yml\", local_params)\n        _create_config_file(self.conf_source, \"base\", \"globals.yml\", base_globals)\n        _create_config_file(self.conf_source, \"local\", \"globals.yml\", local_globals)\n    \n        # Instantiate the OmegaConfigLoader\n        self.loader = OmegaConfigLoader(conf_source=self.conf_source, base_env='base', default_run_env='local')",
        "min_run_count": 2,
        "name": "benchmark_ocl.TimeOmegaConfigLoader.time_loading_parameters",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3187d47ad3445bdf83439512e124e3cde01f0503a3ffa7db9ca7a02e6bc2f7f2",
        "warmup_time": -1
    },
    "benchmark_ocl.TimeOmegaConfigLoader.time_loading_parameters_runtime": {
        "code": "class TimeOmegaConfigLoader:\n    def time_loading_parameters_runtime(self):\n        \"\"\"Benchmark the time to load parameters with runtime configuration\"\"\"\n        self.loader.runtime_params = _generate_params(2001, 2002)\n        self.loader[\"parameters\"]\n\n    def setup(self):\n        # Setup temporary configuration directory with sample config files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.conf_source = Path(self.temp_dir.name)\n    \n        # Create sample config files in the temp directory\n        _create_config_file(self.conf_source, \"base\", \"catalog.yml\", base_catalog)\n        _create_config_file(self.conf_source, \"local\", \"catalog.yml\", local_catalog)\n        _create_config_file(self.conf_source, \"base\", \"parameters.yml\", base_params)\n        _create_config_file(self.conf_source, \"local\", \"parameters.yml\", local_params)\n        _create_config_file(self.conf_source, \"base\", \"globals.yml\", base_globals)\n        _create_config_file(self.conf_source, \"local\", \"globals.yml\", local_globals)\n    \n        # Instantiate the OmegaConfigLoader\n        self.loader = OmegaConfigLoader(conf_source=self.conf_source, base_env='base', default_run_env='local')",
        "min_run_count": 2,
        "name": "benchmark_ocl.TimeOmegaConfigLoader.time_loading_parameters_runtime",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "153be6afe75261c83d15bbc165c10b98af15d3489c722c0f7f8e5c0ce3ca2d59",
        "warmup_time": -1
    },
    "benchmark_ocl.TimeOmegaConfigLoader.time_merge_soft_strategy": {
        "code": "class TimeOmegaConfigLoader:\n    def time_merge_soft_strategy(self):\n        \"\"\"Benchmark the time to load and soft-merge configurations\"\"\"\n        self.loader.merge_strategy = {\"catalog\": \"soft\"}\n        self.loader[\"catalog\"]\n\n    def setup(self):\n        # Setup temporary configuration directory with sample config files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.conf_source = Path(self.temp_dir.name)\n    \n        # Create sample config files in the temp directory\n        _create_config_file(self.conf_source, \"base\", \"catalog.yml\", base_catalog)\n        _create_config_file(self.conf_source, \"local\", \"catalog.yml\", local_catalog)\n        _create_config_file(self.conf_source, \"base\", \"parameters.yml\", base_params)\n        _create_config_file(self.conf_source, \"local\", \"parameters.yml\", local_params)\n        _create_config_file(self.conf_source, \"base\", \"globals.yml\", base_globals)\n        _create_config_file(self.conf_source, \"local\", \"globals.yml\", local_globals)\n    \n        # Instantiate the OmegaConfigLoader\n        self.loader = OmegaConfigLoader(conf_source=self.conf_source, base_env='base', default_run_env='local')",
        "min_run_count": 2,
        "name": "benchmark_ocl.TimeOmegaConfigLoader.time_merge_soft_strategy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "317897f43311426ea9b688e3019361eb5bb1f61f60eca4f763d7a8ec38265ea2",
        "warmup_time": -1
    },
    "benchmark_ocl.TimeOmegaConfigLoaderAdvanced.time_loading_catalog": {
        "code": "class TimeOmegaConfigLoaderAdvanced:\n    def time_loading_catalog(self):\n        \"\"\"Benchmark the time to load the catalog\"\"\"\n        self.loader[\"catalog\"]\n\n    def setup(self):\n        # Setup temporary configuration directory with sample config files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.conf_source = Path(self.temp_dir.name)\n    \n        # Create sample config files in the temp directory\n        _create_config_file(self.conf_source, \"base\", \"catalog.yml\", base_catalog_with_interpolations)\n        _create_config_file(self.conf_source, \"local\", \"catalog.yml\", local_catalog_with_interpolations)\n        _create_config_file(self.conf_source, \"base\", \"parameters.yml\", base_params_with_globals)\n        _create_config_file(self.conf_source, \"base\", \"globals.yml\", base_globals)\n    \n        # Instantiate the OmegaConfigLoader\n        self.loader = OmegaConfigLoader(conf_source=self.conf_source, base_env='base', default_run_env='local')",
        "min_run_count": 2,
        "name": "benchmark_ocl.TimeOmegaConfigLoaderAdvanced.time_loading_catalog",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5499c39a6750c5d527f1a3e8a747fdd5b3128af31640d9d7ee9c72be261e344a",
        "warmup_time": -1
    },
    "benchmark_ocl.TimeOmegaConfigLoaderAdvanced.time_loading_parameters": {
        "code": "class TimeOmegaConfigLoaderAdvanced:\n    def time_loading_parameters(self):\n        \"\"\"Benchmark the time to load parameters with global interpolation\"\"\"\n        self.loader[\"parameters\"]\n\n    def setup(self):\n        # Setup temporary configuration directory with sample config files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.conf_source = Path(self.temp_dir.name)\n    \n        # Create sample config files in the temp directory\n        _create_config_file(self.conf_source, \"base\", \"catalog.yml\", base_catalog_with_interpolations)\n        _create_config_file(self.conf_source, \"local\", \"catalog.yml\", local_catalog_with_interpolations)\n        _create_config_file(self.conf_source, \"base\", \"parameters.yml\", base_params_with_globals)\n        _create_config_file(self.conf_source, \"base\", \"globals.yml\", base_globals)\n    \n        # Instantiate the OmegaConfigLoader\n        self.loader = OmegaConfigLoader(conf_source=self.conf_source, base_env='base', default_run_env='local')",
        "min_run_count": 2,
        "name": "benchmark_ocl.TimeOmegaConfigLoaderAdvanced.time_loading_parameters",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f74ef4eead7a35df856006dbf9e1b72b61ba36b34767525f55bf8c5eabb343f1",
        "warmup_time": -1
    },
    "benchmark_runner.RunnerMemorySuite.mem_runners": {
        "code": "class RunnerMemorySuite:\n    def mem_runners(self, runner):\n        catalog = _get_catalog(runner)\n        test_pipeline = create_compute_bound_pipeline()\n        runner_module = importlib.import_module(\"kedro.runner\")\n        runner_obj = getattr(runner_module, runner)()\n        runner_obj.run(test_pipeline, catalog=catalog)\n\n    def setup(self, *args, **kwargs):\n        data_dir = Path(\"benchmarks/data\")\n        data_dir.mkdir(exist_ok=True, parents=True)\n    \n        # Create a dummy csv\n        with open(data_dir / \"data.csv\", \"w\") as f:\n            f.write(\"col1,col2\\n1,2\\n\")",
        "name": "benchmark_runner.RunnerMemorySuite.mem_runners",
        "param_names": [
            "runner"
        ],
        "params": [
            [
                "'SequentialRunner'",
                "'ThreadRunner'",
                "'ParallelRunner'"
            ]
        ],
        "type": "memory",
        "unit": "bytes",
        "version": "f191d358b753ae48d94151d1f06753c3b2310ecea6ceb86483525c1c5d567f85"
    },
    "benchmark_runner.RunnerMemorySuite.peakmem_runners": {
        "code": "class RunnerMemorySuite:\n    def peakmem_runners(self, runner):\n        catalog = _get_catalog(runner)\n        test_pipeline = create_compute_bound_pipeline()\n        runner_module = importlib.import_module(\"kedro.runner\")\n        runner_obj = getattr(runner_module, runner)()\n        runner_obj.run(test_pipeline, catalog=catalog)\n\n    def setup(self, *args, **kwargs):\n        data_dir = Path(\"benchmarks/data\")\n        data_dir.mkdir(exist_ok=True, parents=True)\n    \n        # Create a dummy csv\n        with open(data_dir / \"data.csv\", \"w\") as f:\n            f.write(\"col1,col2\\n1,2\\n\")",
        "name": "benchmark_runner.RunnerMemorySuite.peakmem_runners",
        "param_names": [
            "runner"
        ],
        "params": [
            [
                "'SequentialRunner'",
                "'ThreadRunner'",
                "'ParallelRunner'"
            ]
        ],
        "type": "peakmemory",
        "unit": "bytes",
        "version": "afc5a9dee40df018f3af8c8a4c0c267246143f7fd5e36297de3bc85917c31472"
    },
    "benchmark_runner.RunnerTimeSuite.time_compute_bound_runner": {
        "code": "class RunnerTimeSuite:\n    def time_compute_bound_runner(self, runner):\n        catalog = _get_catalog(runner)\n        test_pipeline = create_compute_bound_pipeline()\n        runner_module = importlib.import_module(\"kedro.runner\")\n        runner_obj = getattr(runner_module, runner)()\n        runner_obj.run(test_pipeline, catalog=catalog)\n\n    def setup(self, *args, **kwargs):\n        data_dir = Path(\"benchmarks/data\")\n        data_dir.mkdir(exist_ok=True, parents=True)\n    \n        # Create a dummy csv\n        with open(data_dir / \"data.csv\", \"w\") as f:\n            f.write(\"col1,col2\\n1,2\\n\")",
        "min_run_count": 2,
        "name": "benchmark_runner.RunnerTimeSuite.time_compute_bound_runner",
        "number": 0,
        "param_names": [
            "runner"
        ],
        "params": [
            [
                "'SequentialRunner'",
                "'ThreadRunner'",
                "'ParallelRunner'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e2e11c8223a1c952f1d8b9122f6f294d75b35b9aea447efc84ab4daf413bde1d",
        "warmup_time": -1
    },
    "benchmark_runner.RunnerTimeSuite.time_io_bound_runner": {
        "code": "class RunnerTimeSuite:\n    def time_io_bound_runner(self, runner):\n        \"\"\"IO bound pipeline\"\"\"\n        catalog = _get_catalog(runner)\n        test_pipeline = create_io_bound_pipeline()\n        runner_module = importlib.import_module(\"kedro.runner\")\n        runner_obj = getattr(runner_module, runner)()\n        runner_obj.run(test_pipeline, catalog=catalog)\n\n    def setup(self, *args, **kwargs):\n        data_dir = Path(\"benchmarks/data\")\n        data_dir.mkdir(exist_ok=True, parents=True)\n    \n        # Create a dummy csv\n        with open(data_dir / \"data.csv\", \"w\") as f:\n            f.write(\"col1,col2\\n1,2\\n\")",
        "min_run_count": 2,
        "name": "benchmark_runner.RunnerTimeSuite.time_io_bound_runner",
        "number": 0,
        "param_names": [
            "runner"
        ],
        "params": [
            [
                "'SequentialRunner'",
                "'ThreadRunner'",
                "'ParallelRunner'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1a666ba0fcae22a0f83ae26659e6a7e6c56948697b11300cf7124700d2a32c2e",
        "warmup_time": -1
    },
    "benchmark_session.SessionTimeSuite.time_session_run_all_pipelines": {
        "code": "class SessionTimeSuite:\n    def time_session_run_all_pipelines(self):\n        \"\"\"Benchmark creating a session and running all pipelines.\"\"\"\n        with KedroSession.create(\n            project_path=self.project_path, save_on_close=False\n        ) as session:\n            session.run()  # Runs the __default__ pipeline which will run all of them\n\n        def setup(self): #noqa: PLR0912, PLR0915\n            \"\"\"Set up a minimal Kedro project structure for benchmarking.\"\"\"\n    \n            self.project_path = Path(\"benchmarks/session_project\")\n    \n            # Clean up any existing project directory to avoid conflicts\n            if self.project_path.exists():\n                shutil.rmtree(self.project_path)\n    \n            self.project_path.mkdir(parents=True, exist_ok=True)\n            self.original_cwd = Path.cwd()\n    \n            # Change to parent directory to ensure project is created in the right location\n            os.chdir(self.project_path.parent)\n            cli = KedroCLI(self.project_path.parent)\n            try:\n                cli.main(\n                    [\n                        \"new\",\n                        \"--name\",\n                        \"test_project\",\n                        \"--tools\",\n                        \"none\",\n                        \"--example\",\n                        \"no\",\n                    ],\n                    standalone_mode=False,\n                )\n            except SystemExit:\n                pass  # KedroCLI exits after running the command\n            finally:\n                os.chdir(self.original_cwd)  # Return to original directory\n    \n            created_project = None\n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and (potential_dir / \"pyproject.toml\").exists():\n                    try:\n                        with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                            pyproject_data = tomllib.load(f)\n                        if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                            created_project = potential_dir\n                            break\n                    except Exception as e:\n                        logger.debug(f\"Failed to process {potential_dir}: {e}\")\n                        continue\n    \n            if created_project and created_project != self.project_path:\n                for item in created_project.iterdir():\n                    shutil.move(str(item), str(self.project_path / item.name))\n                created_project.rmdir()\n    \n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and potential_dir.name.startswith(\"test-\"):\n                    try:\n                        if (potential_dir / \"pyproject.toml\").exists():\n                            with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                                pyproject_data = tomllib.load(f)\n                            if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                                shutil.rmtree(potential_dir, ignore_errors=True)\n                    except Exception as e:\n                        logger.debug(f\"Failed to clean up {potential_dir}: {e}\")\n    \n            # Bootstrap the project for kedro pipeline create\n            bootstrap_project(self.project_path)\n    \n            with (self.project_path / \"pyproject.toml\").open(\"rb\") as f:\n                pyproject_data = tomllib.load(f)\n            self.package_name = pyproject_data[\"tool\"][\"kedro\"][\"package_name\"]\n            self.package_dir = self.project_path / \"src\" / self.package_name\n    \n            pipeline_names = [\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"]\n            pipelines_dir = self.package_dir / \"pipelines\"\n            for pipeline_name in pipeline_names:\n                pipeline_dir = pipelines_dir / pipeline_name\n                if pipeline_dir.exists():\n                    continue\n    \n                cli = KedroCLI(self.project_path)\n                try:\n                    cli.main(\n                        [\n                            \"pipeline\",\n                            \"create\",\n                            pipeline_name,\n                            \"--skip-config\",\n                        ],\n                        standalone_mode=False,\n                    )\n                except SystemExit:\n                    pass\n                except Exception as e:\n                    logger.debug(f\"Failed to create pipeline '{pipeline_name}': {e}\")\n    \n            dummy_task_code = '''\n    def dummy_task():\n        \"\"\"A simple dummy task that creates and returns a dictionary.\"\"\"\n        result = {}\n        for i in range(100):\n            result[f\"key_{i}\"] = i * 2\n        return result\n    '''\n    \n            for i, pipeline_name in enumerate([\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"], 1):\n                pipeline_file = self.package_dir / \"pipelines\" / pipeline_name / \"pipeline.py\"\n                output_name = f\"output_{i}\"\n                node_name = f\"node_{i}\"\n                pipeline_content = f'''\"\"\"\n    This is a boilerplate pipeline '{pipeline_name}'\n    generated using Kedro\n    \"\"\"\n    \n    from kedro.pipeline import Node, Pipeline\n    \n    {dummy_task_code}\n    \n    def create_pipeline(**kwargs) -> Pipeline:\n        return Pipeline([\n            Node(dummy_task, None, \"{output_name}\", name=\"{node_name}\")\n        ])\n    '''\n                pipeline_file.write_text(pipeline_content)\n    \n            # Update catalog.yml to add output datasets\n            catalog_file = self.project_path / \"conf\" / \"base\" / \"catalog.yml\"\n            if catalog_file.exists():\n                catalog_content = catalog_file.read_text()\n            else:\n                catalog_content = \"\"\n    \n            catalog_content += \"\"\"\n    output_1:\n        type: kedro.io.MemoryDataset\n    \n    output_2:\n        type: kedro.io.MemoryDataset\n    \n    output_3:\n        type: kedro.io.MemoryDataset\n    \n    output_4:\n        type: kedro.io.MemoryDataset\n    \n    output_5:\n        type: kedro.io.MemoryDataset\n    \"\"\"\n            catalog_file.write_text(catalog_content)",
        "min_run_count": 2,
        "name": "benchmark_session.SessionTimeSuite.time_session_run_all_pipelines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "1f8d0ab97841246ca17e2cf083fd3b6b883d7609a436e3e32e756ed665887f0f",
        "warmup_time": -1
    },
    "benchmark_session.SessionTimeSuite.time_session_run_single_pipeline": {
        "code": "class SessionTimeSuite:\n    def time_session_run_single_pipeline(self):\n        \"\"\"Benchmark creating a session and running only one specific pipeline.\"\"\"\n        with KedroSession.create(\n            project_path=self.project_path, save_on_close=False\n        ) as session:\n            session.run(pipeline_name=\"pipeline_1\")\n\n        def setup(self): #noqa: PLR0912, PLR0915\n            \"\"\"Set up a minimal Kedro project structure for benchmarking.\"\"\"\n    \n            self.project_path = Path(\"benchmarks/session_project\")\n    \n            # Clean up any existing project directory to avoid conflicts\n            if self.project_path.exists():\n                shutil.rmtree(self.project_path)\n    \n            self.project_path.mkdir(parents=True, exist_ok=True)\n            self.original_cwd = Path.cwd()\n    \n            # Change to parent directory to ensure project is created in the right location\n            os.chdir(self.project_path.parent)\n            cli = KedroCLI(self.project_path.parent)\n            try:\n                cli.main(\n                    [\n                        \"new\",\n                        \"--name\",\n                        \"test_project\",\n                        \"--tools\",\n                        \"none\",\n                        \"--example\",\n                        \"no\",\n                    ],\n                    standalone_mode=False,\n                )\n            except SystemExit:\n                pass  # KedroCLI exits after running the command\n            finally:\n                os.chdir(self.original_cwd)  # Return to original directory\n    \n            created_project = None\n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and (potential_dir / \"pyproject.toml\").exists():\n                    try:\n                        with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                            pyproject_data = tomllib.load(f)\n                        if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                            created_project = potential_dir\n                            break\n                    except Exception as e:\n                        logger.debug(f\"Failed to process {potential_dir}: {e}\")\n                        continue\n    \n            if created_project and created_project != self.project_path:\n                for item in created_project.iterdir():\n                    shutil.move(str(item), str(self.project_path / item.name))\n                created_project.rmdir()\n    \n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and potential_dir.name.startswith(\"test-\"):\n                    try:\n                        if (potential_dir / \"pyproject.toml\").exists():\n                            with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                                pyproject_data = tomllib.load(f)\n                            if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                                shutil.rmtree(potential_dir, ignore_errors=True)\n                    except Exception as e:\n                        logger.debug(f\"Failed to clean up {potential_dir}: {e}\")\n    \n            # Bootstrap the project for kedro pipeline create\n            bootstrap_project(self.project_path)\n    \n            with (self.project_path / \"pyproject.toml\").open(\"rb\") as f:\n                pyproject_data = tomllib.load(f)\n            self.package_name = pyproject_data[\"tool\"][\"kedro\"][\"package_name\"]\n            self.package_dir = self.project_path / \"src\" / self.package_name\n    \n            pipeline_names = [\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"]\n            pipelines_dir = self.package_dir / \"pipelines\"\n            for pipeline_name in pipeline_names:\n                pipeline_dir = pipelines_dir / pipeline_name\n                if pipeline_dir.exists():\n                    continue\n    \n                cli = KedroCLI(self.project_path)\n                try:\n                    cli.main(\n                        [\n                            \"pipeline\",\n                            \"create\",\n                            pipeline_name,\n                            \"--skip-config\",\n                        ],\n                        standalone_mode=False,\n                    )\n                except SystemExit:\n                    pass\n                except Exception as e:\n                    logger.debug(f\"Failed to create pipeline '{pipeline_name}': {e}\")\n    \n            dummy_task_code = '''\n    def dummy_task():\n        \"\"\"A simple dummy task that creates and returns a dictionary.\"\"\"\n        result = {}\n        for i in range(100):\n            result[f\"key_{i}\"] = i * 2\n        return result\n    '''\n    \n            for i, pipeline_name in enumerate([\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"], 1):\n                pipeline_file = self.package_dir / \"pipelines\" / pipeline_name / \"pipeline.py\"\n                output_name = f\"output_{i}\"\n                node_name = f\"node_{i}\"\n                pipeline_content = f'''\"\"\"\n    This is a boilerplate pipeline '{pipeline_name}'\n    generated using Kedro\n    \"\"\"\n    \n    from kedro.pipeline import Node, Pipeline\n    \n    {dummy_task_code}\n    \n    def create_pipeline(**kwargs) -> Pipeline:\n        return Pipeline([\n            Node(dummy_task, None, \"{output_name}\", name=\"{node_name}\")\n        ])\n    '''\n                pipeline_file.write_text(pipeline_content)\n    \n            # Update catalog.yml to add output datasets\n            catalog_file = self.project_path / \"conf\" / \"base\" / \"catalog.yml\"\n            if catalog_file.exists():\n                catalog_content = catalog_file.read_text()\n            else:\n                catalog_content = \"\"\n    \n            catalog_content += \"\"\"\n    output_1:\n        type: kedro.io.MemoryDataset\n    \n    output_2:\n        type: kedro.io.MemoryDataset\n    \n    output_3:\n        type: kedro.io.MemoryDataset\n    \n    output_4:\n        type: kedro.io.MemoryDataset\n    \n    output_5:\n        type: kedro.io.MemoryDataset\n    \"\"\"\n            catalog_file.write_text(catalog_content)",
        "min_run_count": 2,
        "name": "benchmark_session.SessionTimeSuite.time_session_run_single_pipeline",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d5b732b1ac67844a099d1539639a088b547da65c108b9f747e1a377a9b17343e",
        "warmup_time": -1
    },
    "benchmark_session.SessionTimeSuite.time_session_startup_and_context_load": {
        "code": "class SessionTimeSuite:\n    def time_session_startup_and_context_load(self):\n        \"\"\"Benchmark session creation and context loading.\"\"\"\n        session = KedroSession.create(\n            project_path=self.project_path, save_on_close=False\n        )\n        session.load_context()\n        session.close()\n\n        def setup(self): #noqa: PLR0912, PLR0915\n            \"\"\"Set up a minimal Kedro project structure for benchmarking.\"\"\"\n    \n            self.project_path = Path(\"benchmarks/session_project\")\n    \n            # Clean up any existing project directory to avoid conflicts\n            if self.project_path.exists():\n                shutil.rmtree(self.project_path)\n    \n            self.project_path.mkdir(parents=True, exist_ok=True)\n            self.original_cwd = Path.cwd()\n    \n            # Change to parent directory to ensure project is created in the right location\n            os.chdir(self.project_path.parent)\n            cli = KedroCLI(self.project_path.parent)\n            try:\n                cli.main(\n                    [\n                        \"new\",\n                        \"--name\",\n                        \"test_project\",\n                        \"--tools\",\n                        \"none\",\n                        \"--example\",\n                        \"no\",\n                    ],\n                    standalone_mode=False,\n                )\n            except SystemExit:\n                pass  # KedroCLI exits after running the command\n            finally:\n                os.chdir(self.original_cwd)  # Return to original directory\n    \n            created_project = None\n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and (potential_dir / \"pyproject.toml\").exists():\n                    try:\n                        with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                            pyproject_data = tomllib.load(f)\n                        if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                            created_project = potential_dir\n                            break\n                    except Exception as e:\n                        logger.debug(f\"Failed to process {potential_dir}: {e}\")\n                        continue\n    \n            if created_project and created_project != self.project_path:\n                for item in created_project.iterdir():\n                    shutil.move(str(item), str(self.project_path / item.name))\n                created_project.rmdir()\n    \n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and potential_dir.name.startswith(\"test-\"):\n                    try:\n                        if (potential_dir / \"pyproject.toml\").exists():\n                            with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                                pyproject_data = tomllib.load(f)\n                            if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                                shutil.rmtree(potential_dir, ignore_errors=True)\n                    except Exception as e:\n                        logger.debug(f\"Failed to clean up {potential_dir}: {e}\")\n    \n            # Bootstrap the project for kedro pipeline create\n            bootstrap_project(self.project_path)\n    \n            with (self.project_path / \"pyproject.toml\").open(\"rb\") as f:\n                pyproject_data = tomllib.load(f)\n            self.package_name = pyproject_data[\"tool\"][\"kedro\"][\"package_name\"]\n            self.package_dir = self.project_path / \"src\" / self.package_name\n    \n            pipeline_names = [\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"]\n            pipelines_dir = self.package_dir / \"pipelines\"\n            for pipeline_name in pipeline_names:\n                pipeline_dir = pipelines_dir / pipeline_name\n                if pipeline_dir.exists():\n                    continue\n    \n                cli = KedroCLI(self.project_path)\n                try:\n                    cli.main(\n                        [\n                            \"pipeline\",\n                            \"create\",\n                            pipeline_name,\n                            \"--skip-config\",\n                        ],\n                        standalone_mode=False,\n                    )\n                except SystemExit:\n                    pass\n                except Exception as e:\n                    logger.debug(f\"Failed to create pipeline '{pipeline_name}': {e}\")\n    \n            dummy_task_code = '''\n    def dummy_task():\n        \"\"\"A simple dummy task that creates and returns a dictionary.\"\"\"\n        result = {}\n        for i in range(100):\n            result[f\"key_{i}\"] = i * 2\n        return result\n    '''\n    \n            for i, pipeline_name in enumerate([\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"], 1):\n                pipeline_file = self.package_dir / \"pipelines\" / pipeline_name / \"pipeline.py\"\n                output_name = f\"output_{i}\"\n                node_name = f\"node_{i}\"\n                pipeline_content = f'''\"\"\"\n    This is a boilerplate pipeline '{pipeline_name}'\n    generated using Kedro\n    \"\"\"\n    \n    from kedro.pipeline import Node, Pipeline\n    \n    {dummy_task_code}\n    \n    def create_pipeline(**kwargs) -> Pipeline:\n        return Pipeline([\n            Node(dummy_task, None, \"{output_name}\", name=\"{node_name}\")\n        ])\n    '''\n                pipeline_file.write_text(pipeline_content)\n    \n            # Update catalog.yml to add output datasets\n            catalog_file = self.project_path / \"conf\" / \"base\" / \"catalog.yml\"\n            if catalog_file.exists():\n                catalog_content = catalog_file.read_text()\n            else:\n                catalog_content = \"\"\n    \n            catalog_content += \"\"\"\n    output_1:\n        type: kedro.io.MemoryDataset\n    \n    output_2:\n        type: kedro.io.MemoryDataset\n    \n    output_3:\n        type: kedro.io.MemoryDataset\n    \n    output_4:\n        type: kedro.io.MemoryDataset\n    \n    output_5:\n        type: kedro.io.MemoryDataset\n    \"\"\"\n            catalog_file.write_text(catalog_content)",
        "min_run_count": 2,
        "name": "benchmark_session.SessionTimeSuite.time_session_startup_and_context_load",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6d5a419054cf291ba238d2dc25dfc1baf6951957318cbc184107c0f0c9a6961c",
        "warmup_time": -1
    },
    "benchmark_session.SessionTimeSuite.time_session_startup_only": {
        "code": "class SessionTimeSuite:\n    def time_session_startup_only(self):\n        \"\"\"Benchmark just the session creation/startup time without running.\"\"\"\n        session = KedroSession.create(\n            project_path=self.project_path, save_on_close=False\n        )\n        session.close()\n\n        def setup(self): #noqa: PLR0912, PLR0915\n            \"\"\"Set up a minimal Kedro project structure for benchmarking.\"\"\"\n    \n            self.project_path = Path(\"benchmarks/session_project\")\n    \n            # Clean up any existing project directory to avoid conflicts\n            if self.project_path.exists():\n                shutil.rmtree(self.project_path)\n    \n            self.project_path.mkdir(parents=True, exist_ok=True)\n            self.original_cwd = Path.cwd()\n    \n            # Change to parent directory to ensure project is created in the right location\n            os.chdir(self.project_path.parent)\n            cli = KedroCLI(self.project_path.parent)\n            try:\n                cli.main(\n                    [\n                        \"new\",\n                        \"--name\",\n                        \"test_project\",\n                        \"--tools\",\n                        \"none\",\n                        \"--example\",\n                        \"no\",\n                    ],\n                    standalone_mode=False,\n                )\n            except SystemExit:\n                pass  # KedroCLI exits after running the command\n            finally:\n                os.chdir(self.original_cwd)  # Return to original directory\n    \n            created_project = None\n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and (potential_dir / \"pyproject.toml\").exists():\n                    try:\n                        with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                            pyproject_data = tomllib.load(f)\n                        if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                            created_project = potential_dir\n                            break\n                    except Exception as e:\n                        logger.debug(f\"Failed to process {potential_dir}: {e}\")\n                        continue\n    \n            if created_project and created_project != self.project_path:\n                for item in created_project.iterdir():\n                    shutil.move(str(item), str(self.project_path / item.name))\n                created_project.rmdir()\n    \n            for potential_dir in self.project_path.parent.iterdir():\n                if potential_dir.is_dir() and potential_dir.name.startswith(\"test-\"):\n                    try:\n                        if (potential_dir / \"pyproject.toml\").exists():\n                            with (potential_dir / \"pyproject.toml\").open(\"rb\") as f:\n                                pyproject_data = tomllib.load(f)\n                            if \"tool\" in pyproject_data and \"kedro\" in pyproject_data[\"tool\"]:\n                                shutil.rmtree(potential_dir, ignore_errors=True)\n                    except Exception as e:\n                        logger.debug(f\"Failed to clean up {potential_dir}: {e}\")\n    \n            # Bootstrap the project for kedro pipeline create\n            bootstrap_project(self.project_path)\n    \n            with (self.project_path / \"pyproject.toml\").open(\"rb\") as f:\n                pyproject_data = tomllib.load(f)\n            self.package_name = pyproject_data[\"tool\"][\"kedro\"][\"package_name\"]\n            self.package_dir = self.project_path / \"src\" / self.package_name\n    \n            pipeline_names = [\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"]\n            pipelines_dir = self.package_dir / \"pipelines\"\n            for pipeline_name in pipeline_names:\n                pipeline_dir = pipelines_dir / pipeline_name\n                if pipeline_dir.exists():\n                    continue\n    \n                cli = KedroCLI(self.project_path)\n                try:\n                    cli.main(\n                        [\n                            \"pipeline\",\n                            \"create\",\n                            pipeline_name,\n                            \"--skip-config\",\n                        ],\n                        standalone_mode=False,\n                    )\n                except SystemExit:\n                    pass\n                except Exception as e:\n                    logger.debug(f\"Failed to create pipeline '{pipeline_name}': {e}\")\n    \n            dummy_task_code = '''\n    def dummy_task():\n        \"\"\"A simple dummy task that creates and returns a dictionary.\"\"\"\n        result = {}\n        for i in range(100):\n            result[f\"key_{i}\"] = i * 2\n        return result\n    '''\n    \n            for i, pipeline_name in enumerate([\"pipeline_1\", \"pipeline_2\", \"pipeline_3\", \"pipeline_4\", \"pipeline_5\"], 1):\n                pipeline_file = self.package_dir / \"pipelines\" / pipeline_name / \"pipeline.py\"\n                output_name = f\"output_{i}\"\n                node_name = f\"node_{i}\"\n                pipeline_content = f'''\"\"\"\n    This is a boilerplate pipeline '{pipeline_name}'\n    generated using Kedro\n    \"\"\"\n    \n    from kedro.pipeline import Node, Pipeline\n    \n    {dummy_task_code}\n    \n    def create_pipeline(**kwargs) -> Pipeline:\n        return Pipeline([\n            Node(dummy_task, None, \"{output_name}\", name=\"{node_name}\")\n        ])\n    '''\n                pipeline_file.write_text(pipeline_content)\n    \n            # Update catalog.yml to add output datasets\n            catalog_file = self.project_path / \"conf\" / \"base\" / \"catalog.yml\"\n            if catalog_file.exists():\n                catalog_content = catalog_file.read_text()\n            else:\n                catalog_content = \"\"\n    \n            catalog_content += \"\"\"\n    output_1:\n        type: kedro.io.MemoryDataset\n    \n    output_2:\n        type: kedro.io.MemoryDataset\n    \n    output_3:\n        type: kedro.io.MemoryDataset\n    \n    output_4:\n        type: kedro.io.MemoryDataset\n    \n    output_5:\n        type: kedro.io.MemoryDataset\n    \"\"\"\n            catalog_file.write_text(catalog_content)",
        "min_run_count": 2,
        "name": "benchmark_session.SessionTimeSuite.time_session_startup_only",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "44d6371afc715eee65810736f8b9f384ce86092c1e7988ad3aee0248a2849b85",
        "warmup_time": -1
    },
    "version": 2
}